# ğŸ“’ My Notes on Andrej Karpathy's lectures

This repository contains notebooks based on the great Andrej Karpathy's series **"Neural Networks: Zero to Hero"**

## ğŸ“š Notebooks Overview

### ğŸ¤ğŸ‚ 01-Micrograd
Implementation of [Micrograd](https://github.com/karpathy/micrograd), a compact and didactical deep learning library.
- [**Readme**](karpathings_01_micrograd/README.md)
- [nbğŸ“•](karpathings_01_micrograd/micrograd_01.ipynb): Manual backpropagation of a simple function and a neuron.
- [nbğŸ“˜](karpathings_01_micrograd/micrograd_02.ipynb): Adding more functions to our Micrograd library.
- [nbğŸ“—](karpathings_01_micrograd/micrograd_03.ipynb): Training a small neural network on a simple task.

### ğŸ§‘â€ğŸ¤â€ğŸ§‘ğŸ’¬ 02-Bigram
Implementation of a bigram character-level language model.
- [**Readme**](karpathings_02_bigram/README.md)
- [nbğŸ“•](karpathings_02_bigram/makemore_01_bigrams.ipynb): Building a bigram model to predict the next character based on the previous one.

### ğŸ§ ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ 03-MLP
Implementation of a multi-layer perceptron model, predicting the next character based on the three previous ones.
- [**Readme**](karpathings_03_MLP/README.md)
- [nbğŸ“•](karpathings_03_MLP/makemore_02_MLP.ipynb): Developing a multi-layer perceptron model.
  
### ğŸ§ âš¡ 04-MLP v2
Further improvements and adjustments to the MLP implementation.
- [**Readme**](karpathings_04_MLP/README.md)
- [nbğŸ“•](karpathings_04_MLP/makemore_03.ipynb): Revisiting the MLP implementation with improvements.
- [nbğŸ“˜](karpathings_04_MLP/makemore_03_ipynb_pytorch.ipynb): Implementing the MLP model adding more layers and imitating PyTorch.

## ğŸ”— References

- [Neural Networks: Zero to Hero Lecture Series](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)

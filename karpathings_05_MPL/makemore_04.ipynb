{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# makemore: part 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8134 words\n",
      "['Alegr√≠a-Dulantzi']\n",
      "['alegria-dulantzi']\n"
     ]
    }
   ],
   "source": [
    "#Data load. No changes here\n",
    "\n",
    "#https://datos.gob.es/es/catalogo/a09002970-municipios-de-espana\n",
    "# We will instead be using names of villages/cities in Spain. Only 8k data\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV data\n",
    "df = pd.read_csv(\"Municipis_d_Espanya.csv\", sep=\",\")\n",
    "\n",
    "# Function to clean the names\n",
    "def clean_name(name):\n",
    "    # If there's a slash, take the first part\n",
    "    name = name.split('/')[0]\n",
    "    # If it's in \"Last, First\" format, swap it to \"First Last\"\n",
    "    if ',' in name:\n",
    "        parts = name.split(', ')\n",
    "        if len(parts) == 2:\n",
    "            name = f\"{parts[1]} {parts[0]}\"\n",
    "    return name\n",
    "\n",
    "# Apply the function to clean names\n",
    "df[\"Nom\"] = df[\"Nom\"].apply(clean_name)\n",
    "\n",
    "# Extract only the 'Territorio' column as a list\n",
    "words = df[\"Nom\"].tolist()\n",
    "\n",
    "print(f\"{len(words)} words\")\n",
    "\n",
    "#Simplifying the problem (lowercase and no accents)\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "print(words[:1])\n",
    "words = [re.sub(r'[\\(\\)\\'\"]', '', unidecode.unidecode(word).lower()) for word in words]\n",
    "print(words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ' ', 2: '-', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z', 0: '.'}\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85032, 3]) torch.Size([85032])\n",
      "torch.Size([10606, 3]) torch.Size([10606])\n",
      "torch.Size([10768, 3]) torch.Size([10768])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No changes until here\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def compare_to_pytorch(label, manual_calculated, tensor):\n",
    "    # Check if the values are exactly the same\n",
    "    is_exact = torch.all(manual_calculated == tensor.grad).item()\n",
    "\n",
    "    # Check if the values are approximately the same\n",
    "    is_approximate = torch.allclose(manual_calculated, tensor.grad)\n",
    "\n",
    "    # Calculate the maximum difference between the expected values and the gradients\n",
    "    max_difference = (manual_calculated - tensor.grad).abs().max().item()\n",
    "\n",
    "    # Print the results\n",
    "    print(f'{label:15s} | exactly equal: {str(is_exact):5s} | approximatly equal: {str(is_approximate):5s} | larges difference: {max_difference}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4287\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3797, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Embedding the input characters into vectors\n",
    "embeddings = C[Xb]  # C is the embedding matrix, Xb are the input indices\n",
    "flattened_embeddings = embeddings.view(embeddings.shape[0], -1)  # Flatten embeddings to 2D: (batch_size, embedding_dim)\n",
    "\n",
    "# Step 2: Linear Layer 1 (pre-activation)\n",
    "hidden_pre_bn = flattened_embeddings @ W1 + b1  # Linear transformation (batch_size, hidden_size)\n",
    "\n",
    "# Step 3: Batch Normalization (BN)\n",
    "batch_mean = 1 / batch_size * hidden_pre_bn.sum(0, keepdim=True)  # Calculate batch mean (1, hidden_size)\n",
    "centered_bn = hidden_pre_bn - batch_mean  # Subtract the mean from each hidden pre-activation value\n",
    "centered_bn2=centered_bn**2\n",
    "batch_variance = 1 / (batch_size - 1) * (centered_bn2).sum(0, keepdim=True)  # Calculate batch variance (1, hidden_size)\n",
    "# batch_size-1= Bessel correction. \n",
    "batch_variance_inv = (batch_variance + 1e-5)**-0.5  # Inverse of the standard deviation (1, hidden_size)\n",
    "normalized_bn = centered_bn * batch_variance_inv  # Normalize the batch (batch_size, hidden_size)\n",
    "\n",
    "# Step 4: Apply Scale and Shift (Gamma and Beta) to Batch Normalization\n",
    "hidden_pre_activation = bngain * normalized_bn + bnbias  # Apply learnable scaling (gamma) and shifting (beta)\n",
    "\n",
    "# Step 5: Non-linearity (activation)\n",
    "hidden = torch.tanh(hidden_pre_activation)  # Apply the tanh activation function\n",
    "\n",
    "# Step 6: Linear Layer 2 (output layer)\n",
    "logits = hidden @ W2 + b2  # Final linear transformation to produce logits (batch_size, output_dim)\n",
    "\n",
    "# Step 7: Cross Entropy Loss (manual calculation)\n",
    "logit_max = logits.max(1, keepdim=True).values  # For numerical stability, subtract the max logit\n",
    "norm_logits = logits - logit_max  # Subtract max logits to prevent overflow during exponentiation\n",
    "\n",
    "# Calculate probabilities (softmax)\n",
    "counts_logits = norm_logits.exp()  # Exponentiate the logits to get unnormalized probabilities\n",
    "counts_logits_sum = counts_logits.sum(1, keepdim=True)  # Sum of exponentiated logits (batch_size, 1)\n",
    "count_logits_sum_inv = counts_logits_sum**-1  # Inverse of the sum for normalization (batch_size, 1)\n",
    "probabilities = counts_logits * count_logits_sum_inv  # Normalize to get the actual probabilities (batch_size, output_dim)\n",
    "\n",
    "# Compute log probabilities\n",
    "log_probabilities = probabilities.log()  # Logarithm of probabilities (batch_size, output_dim)\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = -log_probabilities[range(batch_size), Yb].mean()  # Average the negative log likelihood for the true labels\n",
    "\n",
    "# Step 8: Backward Pass\n",
    "for param in parameters:\n",
    "    param.grad = None  # Clear previous gradients\n",
    "\n",
    "# Retain gradients for intermediate variables for debugging or inspection\n",
    "for tensor in [log_probabilities, probabilities, counts_logits, counts_logits_sum, count_logits_sum_inv,\n",
    "               norm_logits, logit_max, logits, hidden, hidden_pre_activation, normalized_bn,\n",
    "               batch_variance_inv, batch_variance, centered_bn,centered_bn2, batch_mean, hidden_pre_bn, flattened_embeddings, embeddings]:\n",
    "    tensor.retain_grad()  # Retain gradients for inspection if needed\n",
    "\n",
    "# Perform backpropagation to compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# Return the final loss value\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## backprop through the whole thing manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlog_probabilities\\nprobabilities\\ninv_logits_sum\\nlogits_sum\\nexp_logits\\nstable_logits\\nlogit_max\\nlogits\\nhidden\\nhidden_pre_activation\\nnormalized_bn\\nbatch_variance_inv\\nbatch_variance\\ncentered_bn\\nbatch_mean\\nflattened_embeddings\\nembeddings\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "log_probabilities\n",
    "probabilities\n",
    "count_logits_sum_inv\n",
    "counts_logits_sum\n",
    "counts_logits\n",
    "norm_logits\n",
    "logit_max\n",
    "logits\n",
    "hidden\n",
    "hidden_pre_activation\n",
    "normalized_bn\n",
    "batch_variance_inv\n",
    "batch_variance\n",
    "centered_bn\n",
    "batch_mean\n",
    "flattened_embeddings\n",
    "embeddings\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 29])\n",
      "log_probabilities | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "#loss = -logprobabilities[range(batch_size), Yb].mean()\n",
    "#loss = -1*(sum(elements))/n_elements\n",
    "#dloss= -1/n_elements\n",
    "\n",
    "print(log_probabilities.shape)\n",
    "\n",
    "d_log_probabilities=torch.zeros_like(log_probabilities)\n",
    "d_log_probabilities[range(batch_size), Yb] = -1/batch_size\n",
    "\n",
    "compare_to_pytorch('log_probabilities', d_log_probabilities, log_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities   | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "#log_probabilities = probabilities.log()\n",
    "#d/dx(log(x)) = 1/x\n",
    "\n",
    "d_probabilities=(1/probabilities)*d_log_probabilities #examples with low prob --> boost grad\n",
    "\n",
    "compare_to_pytorch('probabilities', d_probabilities, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 29])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 29])\n",
      "Inv logits sum  | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "#probabilities = exp_logits * inv_logits_sum  # Normalize to get the actual probabilities (batch_size, output_dim)\n",
    "#2 ops really\n",
    "#   replicate column tensor\n",
    "#   multiplication\n",
    "\n",
    "\n",
    "print(counts_logits.shape)\n",
    "print(count_logits_sum_inv.shape)\n",
    "\n",
    "# c = a * b, but with tensors:\n",
    "# a[3x3] * b[3,1]  ---->\n",
    "# a11*b1  a12*b1  a13*b1\n",
    "# a21*b2  a22*b2  a23*b2\n",
    "# a31*b3  a32*b3  a33*b3\n",
    "# c[3x3]\n",
    "\n",
    "\n",
    "print(d_probabilities.shape)\n",
    "\n",
    "d_count_logits_sum_inv=(counts_logits*d_probabilities).sum(1,keepdim=True)\n",
    "\n",
    "\n",
    "compare_to_pytorch('Inv logits sum', d_count_logits_sum_inv, count_logits_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n",
      "torch.Size([32, 29])\n",
      "Exp sum         | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Exp logits its used twice\n",
    "\n",
    "print(count_logits_sum_inv.shape)\n",
    "print(d_probabilities.shape)\n",
    "\n",
    "d_counts_logits_firstcontrib=(count_logits_sum_inv*d_probabilities)\n",
    "\n",
    "#counts_logits = norm_logits.exp()  # Exponentiate the logits to get unnormalized probabilities\n",
    "#counts_logits_sum = counts_logits.sum(1, keepdim=True)  # Sum of exponentiated logits (batch_size, 1)\n",
    "#count_logits_sum_inv = counts_logits_sum**-1  # Inverse of the sum for normalization (batch_size, 1)\n",
    "#probabilities = counts_logits * count_logits_sum_inv  # Normalize to get the actual probabilities (batch_size, output_dim)\n",
    "\n",
    "#Before counts, we must derivate counts_sum. \"we cannot reach it yet\"\n",
    "#count_logits_sum_inv = counts_logits_sum**-1 \n",
    "#d/dx(1/x) = -1/x^2\n",
    "d_counts_logits_sum=-1/(counts_logits_sum**2)*d_count_logits_sum_inv\n",
    "compare_to_pytorch('Exp sum', d_counts_logits_sum, counts_logits_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 29])\n",
      "torch.Size([32, 1])\n",
      "counts          | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "#counts_logits_sum = counts_logits.sum(1, keepdim=True)  # Sum of exponentiated logits (batch_size, 1)\n",
    "print(counts_logits.shape)\n",
    "print(counts_logits_sum.shape)\n",
    "\n",
    "\n",
    "# a11 a12 a13 ---> b1(= a11 + a12 + a13)\n",
    "# a21 a22 a23 ---> b2(= a21 + a22 + a23)\n",
    "# a31 a32 a33 ---> b3(= a31 + a32 + a33)\n",
    "\n",
    "d_counts_logits_secondcontrib= torch.ones_like(counts_logits)*d_counts_logits_sum\n",
    "\n",
    "d_counts_logits=d_counts_logits_firstcontrib+d_counts_logits_secondcontrib\n",
    "\n",
    "compare_to_pytorch('counts', d_counts_logits, counts_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "#counts_logits = norm_logits.exp()  # Exponentiate the logits to get unnormalized probabilities\n",
    "#d/dx(e^x) = e^x\n",
    "\n",
    "d_norm_logits=norm_logits.exp()*d_counts_logits\n",
    "\n",
    "compare_to_pytorch('norm_logits', d_norm_logits, norm_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n",
      "torch.Size([32, 29])\n",
      "logit_max       | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "#norm_logits = logits - logit_max  # Subtract max logits to prevent overflow during exponentiation\n",
    "\n",
    "print(logit_max.shape)# broacast in the minus\n",
    "print(logits.shape)\n",
    "\n",
    "\n",
    "# c11 c12 c13 = |a11 a12 a13|   |b1|\n",
    "# c21 c22 c23 = |a21 a22 a23| - |b2|\n",
    "# c31 c32 c33 = |a31 a32 a33|   |b1|\n",
    "# e.g c32=a23 -b3\n",
    "\n",
    "d_logit_max=-1*d_norm_logits.sum(1, keepdim=True)\n",
    "\n",
    "\n",
    "compare_to_pytorch('logit_max', d_logit_max, logit_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_logits = 1 * d_norm_logits.clone()\n",
    "d_logits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * d_logit_max\n",
    "\n",
    "compare_to_pytorch('logits', d_logits, logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 29])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([64, 29])\n",
      "torch.Size([29])\n"
     ]
    }
   ],
   "source": [
    "#logits = hidden @ W2 + b2  # Final linear transformation to produce logits (batch_size, output_dim)\n",
    "\n",
    "print(logits.shape)\n",
    "print(hidden.shape)\n",
    "print(W2.shape)\n",
    "print(b2.shape)\n",
    "\n",
    "\n",
    "# Matrix operation: d = a @ b + c\n",
    "# Given:\n",
    "# a = [[a11, a12],\n",
    "#      [a21, a22]]\n",
    "# \n",
    "# b = [[b11, b12],\n",
    "#      [b21, b22]]\n",
    "# \n",
    "# c = [[c1, c2],\n",
    "#      [c1, c2]]\n",
    "#\n",
    "# The resulting matrix d is computed as:\n",
    "# d11 = a11 * b11 + a12 * b21 + c1\n",
    "# d12 = a11 * b12 + a12 * b22 + c2\n",
    "# d21 = a21 * b11 + a22 * b21 + c1\n",
    "# d22 = a21 * b12 + a22 * b22 + c2\n",
    "\n",
    "\n",
    "#hidden=a, W2=b, b2=c\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](dl_da.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden          | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_hidden= d_logits @ W2.T \n",
    "compare_to_pytorch('hidden', d_hidden, hidden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](dl_db.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2              | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_W2= hidden.T@d_logits\n",
    "\n",
    "compare_to_pytorch('W2', d_W2, W2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](dl_dc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2              | exactly equal: True  | approximatly equal: True  | larges difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_b2= d_logits.sum(0, keepdim=True)\n",
    "\n",
    "compare_to_pytorch('b2',d_b2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_pre_activation | exactly equal: False | approximatly equal: True  | larges difference: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "#hidden = torch.tanh(hidden_pre_activation)  # Apply the tanh activation function\n",
    "#a=tanh(z)=(e^z-e^-z)/(e^z+e^-z)\n",
    "#da/dz=1-a**2\n",
    "\n",
    "d_hidden_pre_activation=(1-hidden**2)\n",
    "d_hidden_pre_activation*=d_hidden#chain_rule\n",
    "\n",
    "compare_to_pytorch(\"hidden_pre_activation\", d_hidden_pre_activation, hidden_pre_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized_bn   | exactly equal: False | approximatly equal: True  | larges difference: 4.656612873077393e-10\n",
      "bngain          | exactly equal: False | approximatly equal: True  | larges difference: 1.3969838619232178e-09\n",
      "bnbias          | exactly equal: False | approximatly equal: True  | larges difference: 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "#hidden_pre_activation = bngain * normalized_bn + bnbias  # Apply learnable scaling (gamma) and shifting (beta)\n",
    "\n",
    "d_normalized_bn= bngain*d_hidden_pre_activation\n",
    "\n",
    "compare_to_pytorch(\"normalized_bn\", d_normalized_bn, normalized_bn)\n",
    "\n",
    "d_bngain= (normalized_bn*d_hidden_pre_activation).sum(0, keepdim=True)\n",
    "compare_to_pytorch(\"bngain\", d_bngain, bngain)\n",
    "\n",
    "d_bnbias=d_hidden_pre_activation.sum(0, keepdim=True)\n",
    "compare_to_pytorch(\"bnbias\", d_bnbias, bnbias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([1, 64])\n",
      "batch_variance_inv | exactly equal: False | approximatly equal: True  | larges difference: 2.7939677238464355e-09\n"
     ]
    }
   ],
   "source": [
    "#normalized_bn = centered_bn * batch_variance_inv  # Normalize the batch (batch_size, hidden_size)\n",
    "\n",
    "print(normalized_bn.shape)\n",
    "print(centered_bn.shape)\n",
    "print(batch_variance_inv.shape)\n",
    "\n",
    "d_batch_variance_inv=(centered_bn*d_normalized_bn).sum(0,keepdim=True)\n",
    "\n",
    "compare_to_pytorch(\"batch_variance_inv\", d_batch_variance_inv, batch_variance_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_centered_bn_1st=batch_variance_inv*d_normalized_bn\n",
    "\n",
    "#we follow until we find the other branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_variance  | exactly equal: False | approximatly equal: True  | larges difference: 8.149072527885437e-10\n"
     ]
    }
   ],
   "source": [
    "#batch_variance_inv = (batch_variance + 1e-5)**-0.5  # Inverse of the standard deviation (1, hidden_size)\n",
    "#d/dx(1/x^0.5) = -0.5/x^1.5\n",
    "\n",
    "d_batch_variance = -0.5*(batch_variance+1e-5)**-1.5*d_batch_variance_inv\n",
    "\n",
    "compare_to_pytorch(\"batch_variance\", d_batch_variance, batch_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centered_bn2    | exactly equal: False | approximatly equal: True  | larges difference: 2.546585164964199e-11\n"
     ]
    }
   ],
   "source": [
    "#batch_variance = 1 / (batch_size - 1) * (centered_bn2).sum(0, keepdim=True)  # Calculate batch variance (1, hidden_size)\n",
    "#batch_variance = k * (centered_bn2).sum(0, keepdim=True) \n",
    "\n",
    "\n",
    "k=1/(batch_size-1)\n",
    "d_centered_bn2=k*torch.ones_like(centered_bn2)*d_batch_variance\n",
    "\n",
    "compare_to_pytorch(\"centered_bn2\", d_centered_bn2, centered_bn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centered_bn     | exactly equal: False | approximatly equal: True  | larges difference: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "#centered_bn2=centered_bn**2\n",
    "\n",
    "d_centered_bn_2nd=2*centered_bn*d_centered_bn2\n",
    "\n",
    "d_centered_bn=d_centered_bn_1st+d_centered_bn_2nd\n",
    "\n",
    "compare_to_pytorch(\"centered_bn\", d_centered_bn, centered_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_pre_bn   | exactly equal: False | approximatly equal: False | larges difference: 0.0007873533759266138\n",
      "batch_mean      | exactly equal: False | approximatly equal: True  | larges difference: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "#centered_bn = hidden_pre_bn - batch_mean  # Subtract the mean from each hidden pre-activation value\n",
    "centered_bn.shape, hidden_pre_bn.shape, batch_mean.shape\n",
    "\n",
    "d_hidden_pre_bn=d_centered_bn.clone()\n",
    "d_batch_mean_1st=(-torch.ones_like(centered_bn)*d_centered_bn).sum(0)\n",
    "\n",
    "\n",
    "compare_to_pytorch(\"hidden_pre_bn\", d_hidden_pre_bn, hidden_pre_bn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# makemore: part 5\n",
    "\n",
    "\n",
    "Fixing some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. üå´Ô∏è Fixing loss plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. üßÖ Creating layers for embedding table and concatenate op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. üèóÔ∏è Pytorch containers\n",
    "\n",
    "nn.Sequential ~ list of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8134 words\n",
      "['Alegr√≠a-Dulantzi']\n",
      "['alegria-dulantzi']\n",
      "{1: ' ', 2: '-', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z', 0: '.'}\n",
      "29\n",
      "torch.Size([85032, 3]) torch.Size([85032])\n",
      "torch.Size([10606, 3]) torch.Size([10606])\n",
      "torch.Size([10768, 3]) torch.Size([10768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Data load. No changes here\n",
    "\n",
    "#https://datos.gob.es/es/catalogo/a09002970-municipios-de-espana\n",
    "# We will instead be using names of villages/cities in Spain. Only 8k data\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV data\n",
    "df = pd.read_csv(\"Municipis_d_Espanya.csv\", sep=\",\")\n",
    "\n",
    "# Function to clean the names\n",
    "def clean_name(name):\n",
    "    # If there's a slash, take the first part\n",
    "    name = name.split('/')[0]\n",
    "    # If it's in \"Last, First\" format, swap it to \"First Last\"\n",
    "    if ',' in name:\n",
    "        parts = name.split(', ')\n",
    "        if len(parts) == 2:\n",
    "            name = f\"{parts[1]} {parts[0]}\"\n",
    "    return name\n",
    "\n",
    "# Apply the function to clean names\n",
    "df[\"Nom\"] = df[\"Nom\"].apply(clean_name)\n",
    "\n",
    "# Extract only the 'Territorio' column as a list\n",
    "words = df[\"Nom\"].tolist()\n",
    "\n",
    "print(f\"{len(words)} words\")\n",
    "\n",
    "#Simplifying the problem (lowercase and no accents)\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "print(words[:1])\n",
    "words = [re.sub(r'[\\(\\)\\'\"]', '', unidecode.unidecode(word).lower()) for word in words]\n",
    "print(words[:1])\n",
    "\n",
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)\n",
    "\n",
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These classes implement the same API as nn.Module in PyTorch\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "class Linear:\n",
    "    \"\"\"Simple Linear layer implementation (y = wx + b)\"\"\"\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        # Initialize weights using Kaiming initialization (scaled by fan_in)\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # Forward pass: matrix multiplication (and bias addition if present)\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        # Return trainable parameters\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "class BatchNorm1d:\n",
    "    \"\"\"Batch Normalization layer for stabilizing training\"\"\"\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps  # Small constant for avoid /0\n",
    "        self.momentum = momentum  # For running statistics update\n",
    "        self.training = True\n",
    "        # Learnable parameters\n",
    "        self.gamma = torch.ones(dim)   # Scale parameter\n",
    "        self.beta = torch.zeros(dim)   # Shift parameter\n",
    "        # Running statistics for inference\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if self.training:\n",
    "            # During training: use batch statistics\n",
    "            xmean = x.mean(0, keepdim=True)  # Batch mean\n",
    "            xvar = x.var(0, keepdim=True)    # Batch variance\n",
    "            \n",
    "            # Update running statistics for inference\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        else:\n",
    "            # During inference: use running statistics\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        \n",
    "        # Normalize and apply learnable parameters\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)  # Normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta          # Scale and shift\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "class Tanh:\n",
    "    \"\"\"Hyperbolic tangent activation function\"\"\"\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []  # No trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßÖ\n",
    "\n",
    "# One more time doing it pytorch-like\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        # Create a learnable embedding table/matrix\n",
    "        # num_embeddings: total number of unique tokens/items in vocabulary\n",
    "        # embedding_dim: dimension of each embedding vector\n",
    "        # shape: (vocabulary_size, embedding_dimension)\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "        \n",
    "    def __call__(self, IX):\n",
    "        # IX is a tensor of indices into the embedding table\n",
    "        # Each index selects a row from the embedding weight matrix\n",
    "        # For example, if IX contains [3, 1, 4], this selects rows 3, 1, and 4\n",
    "        # Returns tensor containing embedding vectors for each index\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "        \n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "class Flatten:      \n",
    "    def __call__(self, x):\n",
    "        self.out = x.view(x.shape[0],-1)\n",
    "        return self.out\n",
    "        \n",
    "    def parameters(self):\n",
    "        # This layer has no learnable parameters\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üèóÔ∏è\n",
    "\n",
    "class Sequential:\n",
    "  \n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18590\n"
     ]
    }
   ],
   "source": [
    "# Model architecture parameters\n",
    "n_embd = 10      # Dimension of character embeddings\n",
    "n_hidden = 300   # Number of neurons in hidden layers\n",
    "\n",
    "torch.manual_seed(42);\n",
    "\n",
    "#C = torch.randn((vocab_size, n_embd))# üßÖ\n",
    "\n",
    "#üèóÔ∏è layers = [  # Deleting naked list of layers. We now have a model object\n",
    "model = Sequential([\n",
    "Embedding(vocab_size, n_embd),# üßÖ\n",
    "Flatten(),# üßÖ\n",
    "Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "Linear(n_hidden, vocab_size, bias=False),\n",
    "])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Scale down the last layer to make initial predictions less confident\n",
    "    model.layers[-1].weight *= 0.1\n",
    "\n",
    "# Collect all trainable parameters\n",
    "#üßÖparameters = '''[C]''' + [p for layer in layers for p in layer.parameters()]\n",
    "\n",
    "#üèóÔ∏èparameters = [p for layer in layers for p in layer.parameters()]\n",
    "parameters = model.parameters()#üèóÔ∏è\n",
    "\n",
    "print(sum(p.nelement() for p in parameters))  # Total number of parameters\n",
    "\n",
    "# Enable gradient computation for all parameters\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3780\n",
      "   5000/ 200000: 1.8779\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m     28\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Parameter update with learning rate decay\u001b[39;00m\n\u001b[1;32m     32\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m150000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.01\u001b[39m  \u001b[38;5;66;03m# Reduce learning rate after 150k steps. Commenting this after bad results\u001b[39;00m\n",
      "File \u001b[0;32m~/nn_zero2hero/venv/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nn_zero2hero/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nn_zero2hero/venv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training hyperparameters\n",
    "max_steps = 200000\n",
    "batch_size = 64\n",
    "lossi = []  # Store loss history (log10)\n",
    "\n",
    "for i in range(max_steps):\n",
    "    \n",
    "    # Create minibatch by random sampling\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]  # batch of inputs and targets\n",
    "    \n",
    "    # Forward pass--->\n",
    "    x=Xb\n",
    "    #üßÖemb = C[Xb]  # Transform characters into embedding vectors\n",
    "    #üßÖx = emb.view(emb.shape[0], -1)  # Flatten the embeddings for the linear layer\n",
    "    \n",
    "    #üèóÔ∏èfor layer in layers:\n",
    "    #üèóÔ∏è    x = layer(x)  # Pass through each layer sequentially\n",
    "    \n",
    "\n",
    "    logits=model(x)#üèóÔ∏è\n",
    "    \n",
    "    loss = F.cross_entropy(logits, Yb)  # Calculate cross entropy loss\n",
    "    \n",
    "    # Backward pass<----  \n",
    "    # Zero all parameter gradients\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Parameter update with learning rate decay\n",
    "    lr = 0.1 if i < 150000 else 0.01  # Reduce learning rate after 150k steps. Commenting this after bad results\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad  # Simple SGD update\n",
    "    \n",
    "    # Monitoring and logging\n",
    "    if i % 5000 == 0:  # Print progress every 5k steps\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    \n",
    "    # Store loss in log scale\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.training=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc86a398ec0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#probably our batch size is too small. we got lucky batches or unlucky batches\n",
    "\n",
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1000]' is invalid for input of size 6794",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m lossi_tensor\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(lossi)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Reshape the tensor and calculate mean values for plotting:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# view(-1, 1000) reshapes the tensor into rows of 1000 values each\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# mean(1) calculates the mean along dimension 1 (across each row)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#    - This gives you the average loss for each group of 1000 iterations\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mlossi_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1000]' is invalid for input of size 6794"
     ]
    }
   ],
   "source": [
    "#üå´Ô∏è Fixing loss plot\n",
    "\n",
    "lossi_tensor=torch.tensor(lossi)\n",
    "# Reshape the tensor and calculate mean values for plotting:\n",
    "# view(-1, 1000) reshapes the tensor into rows of 1000 values each\n",
    "# mean(1) calculates the mean along dimension 1 (across each row)\n",
    "#    - This gives you the average loss for each group of 1000 iterations\n",
    "plt.plot(lossi_tensor.view(-1,1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train <built-in method item of Tensor object at 0x7fc8bf0a6940>\n",
      "val <built-in method item of Tensor object at 0x7fc8bf064140>\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "    }[split]\n",
    "    \n",
    "    #üèóÔ∏è emb = C[x] # (N, block_size, n_embd)\n",
    "    #üèóÔ∏è x = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "    #üèóÔ∏è for layer in layers:\n",
    "    #üèóÔ∏è     x=layer(x)\n",
    "    #üèóÔ∏è loss=F.cross_entropy(x,y)\n",
    "\n",
    "    #üèóÔ∏è\n",
    "    logits=model(x)\n",
    "    loss=F.cross_entropy(logits,y)\n",
    "\n",
    "    print(split,loss.item)\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "montera.\n",
      "santales de villares.\n",
      "vilesa.\n",
      "juiconenqueracera.\n",
      "forti de vinonoralotazalan.\n",
      "cimialemocerelles a-adenijara.\n",
      "san juanigro de rurinarblia de serramo.\n",
      "el arucuno.\n",
      "fortirafo algaretiguesas de buas.\n",
      "penoviancoquelo de la sempo.\n",
      "rabajo.\n",
      "navios.\n",
      "pillarenca del vallar cra.\n",
      "santin.\n",
      "santa.\n",
      "villosa.\n",
      "aldega.\n",
      "rez.\n",
      "guenas mortia.\n",
      "canal.\n",
      "cortin.\n",
      "duz de bledrimerio.\n",
      "brit dello.\n",
      "el sigaan mi lle de gurgorre.\n",
      "cordejueyner.\n",
      "cos.\n",
      "cinevo.\n",
      "bringoo arcobivardez.\n",
      "condalaran.\n",
      "cadlagranavarra.\n",
      "bapa.\n",
      "tellodesa.\n",
      "tolillahuentercasal del tejo.\n",
      "villanomenc munco.\n",
      "manadarzarral de farrias.\n",
      "veira.\n",
      "o banyo.\n",
      "tlia de crada.\n",
      "santadiles.\n",
      "ajera.\n",
      "el reixera.\n",
      "can.\n",
      "cin.\n",
      "es.\n",
      "murias calar de la frentejarzas de artin.\n",
      "baia.\n",
      "o cruel valmoyoles.\n",
      "bie.\n",
      "esoros.\n",
      "pilla.\n",
      "mura.\n",
      "hargallo.\n",
      "mur.\n",
      "bineca.\n",
      "saco.\n",
      "cro.\n",
      "muris.\n",
      "ubosa de lar de lragoi.\n",
      "villo.\n",
      "benabreanta rean.\n",
      "moria del modeprion.\n",
      "erterreros.\n",
      "balbuela.\n",
      "haro de la de sies campresmos.\n",
      "villas cro.\n",
      "cas.\n",
      "kerecuenyena.\n",
      "terra de pedrepillafrajos.\n",
      "cerc.\n",
      "poltomera.\n",
      "afuentebaltertin.\n",
      "villa.\n",
      "tiko.\n",
      "villas de guan.\n",
      "corce.\n",
      "pkanueva de las del cabheda de gal de muristarri de arias.\n",
      "casazes.\n",
      "cartigo.\n",
      "counava de ribuenadanyarralbel.\n",
      "chenuevierra de fel.\n",
      "hores.\n",
      "benaroa de ason.\n",
      "corho renoarloren.\n",
      "moradar.\n",
      "cobia de ligodejoranalgarriilnalva de yena.\n",
      "buzo.\n",
      "guas morevocortes.\n",
      "sanojovilaat de bumarco de llo.\n",
      "arc.\n",
      "morilaco.\n",
      "aluera.\n",
      "viguesta.\n",
      "joradrano.\n",
      "sego.\n",
      "tig.\n",
      "bena.\n",
      "ellanordonellavente.\n",
      "enirrein.\n",
      "ola de la saes.\n",
      "canillas.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "        #üèóÔ∏è emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "        #üèóÔ∏è x = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "        #üèóÔ∏è for layer in layers:\n",
    "        #üèóÔ∏è     x=layer(x)\n",
    "        logits=model(torch.tensor([context]))\n",
    "        probs= F.softmax(logits,dim=1)\n",
    "\n",
    "        ix=torch.multinomial(probs, num_samples=1).item()\n",
    "        context=context[1:]+[ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
